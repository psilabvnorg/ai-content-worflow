# TikTok News Video Generator üé¨

Automated pipeline to convert Vietnamese news articles into TikTok-ready vertical videos (9:16) with AI voice-over, subtitles, and customizable PowerPoint intro templates.

## Features

- üì∞ **Auto-crawl** news from VnExpress, Tien Phong
- ü§ñ **AI Summarization** using qwen3-vl:4b via Ollama (chunked processing for long articles)
- üé§ **GPU-accelerated TTS** with VieNeu-TTS (multiple Vietnamese voices)
- üé¨ **Pan effects** with blurred background for images/videos
- üí¨ **Auto-subtitles** with Whisper word-level timing + intelligent text alignment
- üé® **PowerPoint Templates** - design custom intros in PowerPoint
- üéµ **Background music** with typing SFX during intro
- üìÑ **Summary Export** in text and JSON formats
- üì± **TikTok-ready** 1080x1920 MP4 output (~60-90 seconds)

## System Requirements

- Python 3.10+
- NVIDIA GPU with CUDA support (RTX 5070 Ti or similar recommended)
- ~10GB disk space for models
- Ubuntu/Linux (tested on Ubuntu 22.04)

## Installation

### 1. Clone and Setup Environment

```bash
git clone <repo>
cd ai-content-tiktok

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install Python dependencies
pip install -r requirements.txt
```

### 2. Install System Dependencies

```bash
# FFmpeg for audio/video processing
sudo apt install ffmpeg

# espeak-ng for Vietnamese phonemization (required by VieNeu-TTS)
sudo apt install espeak-ng

# LibreOffice for PowerPoint template rendering
sudo apt install libreoffice
```

### 3. Install Ollama and qwen3-vl:4b (Summarization)

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve

# Pull qwen3-vl:4b model (~2.5GB)
ollama pull qwen3-vl:4b
```

Verify installation:
```bash
ollama list
# Should show: qwen3-vl:4b
```

### 4. Install VieNeu-TTS Model (Text-to-Speech)

```bash
# Install vieneu package
pip install vieneu

# The model will auto-download on first run, or manually download:
python -c "
from vieneu import Vieneu
tts = Vieneu(backbone_repo='pnnbao-ump/VieNeu-TTS-0.3B')
print('VieNeu-TTS downloaded successfully')
"
```

For local model (faster loading):
```bash
# Clone to models directory
git lfs install
git clone https://huggingface.co/pnnbao-ump/VieNeu-TTS models/VieNeu-TTS
```

### 5. Install Whisper Model (Subtitle Transcription)

```bash
# Install openai-whisper
pip install openai-whisper

# The model downloads automatically on first run
# System will try base model first (~140MB), then fall back to smaller models if GPU memory is limited
# Or pre-download:
python -c "import whisper; whisper.load_model('base')"
```

### 6. Verify GPU Setup

```bash
python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')
"
```

## Model Summary

| Model | Purpose | Size | Location |
|-------|---------|------|----------|
| qwen3-vl:4b | News summarization | ~2.5GB | Ollama (~/.ollama/models) |
| VieNeu-TTS-0.3B | Vietnamese TTS | ~1.2GB | HuggingFace cache or models/VieNeu-TTS |
| Whisper base | Subtitle transcription | ~140MB | ~/.cache/whisper |

## Quick Start

```bash
# Basic usage
python src/main.py --url "https://vnexpress.net/..."

# With custom intro template (separate 5-second intro with fade out)
python src/main.py --url "https://vnexpress.net/..." --template "psi" --intro-duration 5

# Intro overlay mode (intro stays as transparent overlay for entire video)
python src/main.py --url "https://vnexpress.net/..." --template 0 --intro-duration none

# With custom voice
python src/main.py --url "https://vnexpress.net/..." --voice huong
```

## CLI Arguments

| Argument | Description | Default |
|----------|-------------|---------|
| `--url` | News article URL | (prompted) |
| `--image-dir` | Custom directory for images | (from article) |
| `--broll-dir` | Directory with B-roll videos (.mp4, .mov) | None |
| `--voice` | Voice name (see table below) | binh |
| `--template` | Intro template (slide name or index from PowerPoint) | None |
| `--intro-duration` | Intro duration in seconds (separate clip with fade), or "none" for overlay mode (stays entire video) | 3 |
| `--output` | Output video name (without extension) | auto-generated |

## PowerPoint Intro Templates

Design custom intro templates in `templates/intro_template.pptx`:

1. Each slide = one intro template (e.g., slide 1 for channel A, slide 2 for channel B)
2. Add `{{TITLE_HERE}}` text box for dynamic title insertion
3. Article image is placed at the bottom layer automatically
4. All styling (transparency, colors, icons) is preserved

**Intro Modes:**
- **Separate intro** (`--intro-duration 3`): Intro plays as separate clip with fade out, then content starts
- **Overlay mode** (`--intro-duration none`): Intro stays as transparent overlay at top while images/videos transition underneath for entire video

```bash
# Use slide by name (searches slide text)
python src/main.py --url "..." --template "psi"

# Use slide by index (0-based)
python src/main.py --url "..." --template 0

# Overlay mode - intro stays entire video
python src/main.py --url "..." --template "psi" --intro-duration none
```

## Available Voices

| Voice | Gender | Region |
|-------|--------|--------|
| binh, tuyen | Male | Northern |
| nguyen, son, vinh | Male | Southern |
| huong, ly, ngoc | Female | Northern |
| doan, dung | Female | Southern |

## Project Structure

```
ai-content-tiktok/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ crawler/news_crawler.py       # Web scraping
‚îÇ   ‚îú‚îÄ‚îÄ processor/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ content_summarizer.py     # qwen3-vl:4b chunked summarization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ news_refiner.py           # Grammar/spelling refinement
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_corrector.py         # Diacritics correction
‚îÇ   ‚îú‚îÄ‚îÄ media/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tts_generator.py          # VieNeu-TTS (GPU)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_composer.py         # Video composition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intro_renderer.py         # PowerPoint template rendering
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ subtitle_generator.py     # Whisper + intelligent alignment
‚îÇ   ‚îî‚îÄ‚îÄ main.py                       # Main orchestrator
‚îú‚îÄ‚îÄ templates/intro_template.pptx     # PowerPoint intro templates
‚îú‚îÄ‚îÄ assets/                           # Logo, icons, music, SFX
‚îú‚îÄ‚îÄ models/                           # Local model files (optional)
‚îÇ   ‚îî‚îÄ‚îÄ VieNeu-TTS/                   # Local TTS model
‚îî‚îÄ‚îÄ output/                           # Generated videos, audio, summaries
```

## Processing Pipeline

```
1. Crawl Article ‚Üí 2. Chunk & Summarize (Qwen3:4B) ‚Üí 3. Refine Text ‚Üí
4. Final Cleanup ‚Üí 5. Generate TTS (GPU) ‚Üí 6. Whisper Word-Level Timing ‚Üí
7. Intelligent Subtitle Alignment ‚Üí 8. Render Intro (PowerPoint) ‚Üí 9. Compose Video
```

### Subtitle Synchronization

The subtitle system uses a hybrid approach for perfect timing:

1. **Whisper** extracts precise word-level timestamps from audio (uses base model with automatic fallback to smaller models if GPU memory is limited)
2. **Corrected script** provides accurate Vietnamese text (no transcription errors)
3. **Intelligent alignment** maps corrected words to Whisper timing using:
   - Direct word matching (exact matches)
   - Fuzzy matching (similar words)
   - Proportional timing fallback (when no match found)

This ensures subtitles are perfectly synchronized with voice-over while displaying correct Vietnamese text.

## Text Processing

The summarizer automatically handles:
- **Numbers**: `1.890` ‚Üí `1890` (Vietnamese thousand separator)
- **Dates**: `8/1` ‚Üí `m√πng 8 th√°ng 1`
- **Stuck words**: `ch·ª©ng kho√°nkh·ªüi` ‚Üí `ch·ª©ng kho√°n kh·ªüi`
- **Incomplete sentences**: Ensures proper ending punctuation

## Output Specifications

- **Resolution**: 1080x1920 (9:16 vertical)
- **Format**: MP4 (H.264 codec)
- **Frame Rate**: 30 FPS
- **Duration**: ~60-90 seconds
- **Audio**: AAC codec
- **Effects**: Pan left-to-right with blurred background

## Troubleshooting

### Ollama connection failed
```bash
# Start Ollama service
ollama serve

# Check if running
curl http://localhost:11434/api/tags
```

### TTS too slow / No GPU
```bash
# Check CUDA
python -c "import torch; print(torch.cuda.is_available())"

# If False, reinstall PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### espeak-ng not found
```bash
sudo apt install espeak-ng
```

### PowerPoint template not rendering
```bash
# Install LibreOffice
sudo apt install libreoffice

# Test conversion
libreoffice --headless --convert-to png templates/intro_template.pptx
```

### Whisper model download fails
```bash
# Manual download (base model - good balance of accuracy and speed)
python -c "import whisper; whisper.load_model('base')"

# System automatically falls back to smaller models (small, tiny) if GPU memory is limited
# Or force CPU mode if needed
python -c "import whisper; whisper.load_model('base', device='cpu')"
```

### Summary too short or cut off
- The chunked summarizer splits long articles into parts
- Each chunk is summarized separately then combined
- Target is ~350 words (~60-90 seconds of speech)

## License

Open source - Free for commercial use

## Credits

- **Summarization**: qwen3-vl:4b via Ollama
- **TTS**: VieNeu-TTS (GPU-accelerated Vietnamese)
- **Transcription**: OpenAI Whisper (adaptive model selection)
- **Video**: MoviePy

---

Made with ‚ù§Ô∏è for Vietnamese content creators
